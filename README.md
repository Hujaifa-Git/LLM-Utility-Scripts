# LLM_Utility_Scripts

This repository contains some utility scripts that assist in working with Large Language Models. 

## Scripts

### llm_generation.ipynb
Explains hyper-parameters for the Generation config of LLM and what effect will happend if we tune each of them
### Increase_Inference_Speed_LLM.py
Some general techniques to increase the inference speed of LLM, using Quantization, Flash attention and Flash attention 2. Therer are more techniques but they require specific architectures to work.
